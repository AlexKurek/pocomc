{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the Model Evidence using Bridge Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous tutorial we showed how one can esstimate the **model evidence** $\\mathcal{Z}$ for two models in order to perform **Bayesian model comparison**. To this end, we computed the **Bayes factor** as the ratio of the two model evidences (i.e. one for each model). The estimates of $\\mathcal{Z}$ which we used were the ones provided by ``pocoMC`` at the end of the *PMC* run.\n",
    "\n",
    "**There is however another way of estimating the model evidence $\\mathcal{Z}$, called Bridge Sampling, that is much more accurate.**\n",
    "\n",
    "Bridge sampling estimates the model evidence $\\mathcal{Z}$ using an auxiliary distribution $\\mathcal{Q}(\\theta)$, in addition to the posterior distribution $\\mathcal{P}(\\theta)$. The basic idea is to use samples from both the auxiliary and the posterior distribution in order to get the evidence:\n",
    "\n",
    "$$\n",
    "\\mathcal{Z}_{\\mathcal{P}} = \\frac{\\mathbb{E}_{\\mathcal{Q}}[\\alpha(\\theta)\\mathcal{P}(\\theta)]}{\\mathbb{E}_{\\mathcal{P}}[\\alpha(\\theta)\\mathcal{Q}(\\theta)]}\\mathcal{Z}_{\\mathcal{Q}}\n",
    "$$\n",
    "\n",
    "where $\\alpha(\\theta)$ is an arbitrary function, called *bridge function, which controls the efficiency of the estimator. The use of samples from both distributions is characteristic of Bridge Sampling, unlike other estimators (e.g. Importance Sampling, Harmonic Mean, Nested Sampling, etc.) which rely on a single distribution. This important difference allows Bridge Sampling to constrain $\\mathcal{Z}$ both from above and below thus resulting in very accurate and unbiased estimates.\n",
    "\n",
    "In ``pocoMC`` we implement the powerful [**Gaussianised Bridge Sampling**](https://arxiv.org/abs/1912.06073) algorithm which utilises the *Normalising Flow (NF)* as the auxiliary distribution. Furthermore, the bridge function $\\alpha(\\theta)$ has been chosen such that the estimate of $\\mathcal{Z}$ is optimal (i.e. lowest variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the likelihood and prior\n",
    "\n",
    "For this example we will use a simple 2-D Rosenbrock (banana) distribution with a uniform prior $\\mathcal{U}(-5,5)$. The reason for this is that we know the analytical value of $\\log\\mathcal{Z}_{an} = -5.804$. Of course the method of Bridge Sampling can be applied to any posterior distribution with a proper prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pocomc as pc\n",
    "np.random.seed(42)\n",
    "\n",
    "n_dim = 2\n",
    "\n",
    "low = -5.0\n",
    "high = 5.0\n",
    "\n",
    "lower = np.full(n_dim, low) # lower bound of the prior\n",
    "upper = np.full(n_dim, high) # upper bound of the prior\n",
    "bound = np.array((lower, upper)).T\n",
    "diff = bound[:, 1] - bound[:, 0]\n",
    "const = np.sum(np.log(diff))\n",
    "\n",
    "def log_prior(x):\n",
    "    if np.any(x>high) or np.any(x<low):\n",
    "        return -np.inf \n",
    "    else:\n",
    "        return -const\n",
    "\n",
    "# vectorised loglikelihood\n",
    "def log_like_vec(x):\n",
    "\n",
    "    f = np.sum(100.0*(x[:,::2]**2.0 - x[:,1::2])**2.0 + (x[:,::2] - 1.0)**2.0, axis=1)\n",
    "\n",
    "    return - f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running PMC\n",
    "\n",
    "The next step is to actually sample from the posterior using PMC as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 28it [01:56,  4.15s/it, beta=1, calls=57000, ESS=0.959, logZ=-5.77, accept=0.258, N=2, scale=1.27, corr=0.637]      \n",
      "Iter: 9it [00:00, 10.60it/s, beta=1, calls=75000, ESS=0.95, logZ=-5.77, accept=0.238, N=2, scale=1.34, corr=0.656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logZ estimated using PMC :  -5.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_particles = 1000\n",
    "\n",
    "prior_samples = np.random.uniform(low, high, size=(n_particles, n_dim))\n",
    "\n",
    "sampler = pc.Sampler(n_particles,\n",
    "                     n_dim, \n",
    "                     log_like_vec, \n",
    "                     log_prior, \n",
    "                     bounds=bound,\n",
    "                     random_state=42\n",
    "                     )\n",
    "\n",
    "sampler.run(prior_samples)\n",
    "\n",
    "sampler.add_samples(9000)\n",
    "\n",
    "print(\"logZ estimated using PMC : \", np.round(sampler.results[\"logz\"][-1],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bridge Sampling\n",
    "\n",
    "Now that we have successfuly sampled the posterior, we can move on to estimate the log model evidence $\\log\\mathcal{Z}$ using Bridge Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logZ estimated using Bridge Sampling :  -5.801  +-  0.003\n"
     ]
    }
   ],
   "source": [
    "logz_bs, logz_bs_error = sampler.bridge_sampling()\n",
    "\n",
    "print(\"logZ estimated using Bridge Sampling : \", np.round(logz_bs,3), \" +- \", np.round(logz_bs_error,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bridge Sampling estimate is much closer to the true value of $\\log\\mathcal{Z}_{a}-5.804$ and the error-bar looks reasonable. Although the difference between the two methods is small in this example, this is not generally the case. In particular, for higher dimensional problems,  Bridge Sampling should always be preferred!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('dev-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ac2f4c61c266bb52a03065be1066df13d67bb46f44682beb50676a7747401df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}